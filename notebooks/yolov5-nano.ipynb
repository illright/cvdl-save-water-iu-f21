{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CVDL: YOLOv5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sN5_ewYDplUr",
        "HK01_ByOrpcy"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brvLsVAlo2Qu"
      },
      "source": [
        "# YOLO, so Save Water â€“ YOLOv5 Nano edition\n",
        "\n",
        "This notebook will assess the performance of YOLOv5 for detection of taps in pictures, differentiating between taps with and without running water.\n",
        "\n",
        "This notebook is heavily based on the notebook from [Ultralytics's tutorial](https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN5_ewYDplUr"
      },
      "source": [
        "## Step 0. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtljQo-kpz-i"
      },
      "source": [
        "We will use Roboflow to manage conversion of the dataset to a format that is appropriate for YOLOv5. Roboflow provides a nice library of bindings for Python to easily extract the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGwD_Wp1p8Yy"
      },
      "source": [
        "!pip install roboflow --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkBDW8yhqJ_j"
      },
      "source": [
        "Now we will clone the YOLOv5 repository and install its dependencies:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82E-tI4kqP0C"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5\n",
        "%cd yolov5\n",
        "!pip install -r requirements.txt --quiet\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from IPython.display import Image, clear_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HK01_ByOrpcy"
      },
      "source": [
        "## Step 1. Downloading the custom dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CcdTyINrNky"
      },
      "source": [
        "Here we will fetch the custom dataset. It is available in my account in Roboflow.\n",
        "\n",
        "**Disclaimer**: the API key in the code below is revoked, the data cannot be accessed with it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R2wGvjd4Z_92"
      },
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"3FpNhe5OoFPSZw7qdSq7\")\n",
        "project = rf.workspace().project(\"yolo--so-save-water\")\n",
        "dataset = project.version(2).download(\"yolov5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOjJI024sSRo"
      },
      "source": [
        "## Step 2. Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOmNQ6cpsqvp"
      },
      "source": [
        "!python train.py --img 640 --batch 16 --epochs 1000 --data {dataset.location}/data.yaml --weights yolov5n.pt --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-OJMgDEG8-b"
      },
      "source": [
        "# Step 3. Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J97rhfFuHFj7"
      },
      "source": [
        "Let's now test how our trained model performs on unseen data from the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft4SjZxaHMLR"
      },
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.6 --source {dataset.location}/test/images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld2wvnN0HRY4"
      },
      "source": [
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "for imageName in glob.glob('/content/yolov5/runs/detect/exp3/*.jpg'):\n",
        "    display(Image(filename=imageName))\n",
        "    print('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5AIQBXfiaqB"
      },
      "source": [
        "As we can see from the images above, the model performance is not good. The guesses aren't confident enough, so with the 0.6 threshold, many of them simply do not come through."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdts15tHHcNh"
      },
      "source": [
        "# Step 4. Evaluating metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBOA6my-Hit8"
      },
      "source": [
        "Metrics are plotted by TensorBoard. It seems that mAP isn't too bad, reaching around 0.95 in peaks. However, that doesn't seem to transfer to the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vzo8L8THiA1"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}